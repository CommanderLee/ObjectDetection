@inproceedings{Keller2011,
author = {Keller, C. G. and Enzweiler, M. and Gavrila, D. M.},
booktitle = {2011 IEEE Intelligent Vehicles Symposium (IV)},
doi = {10.1109/IVS.2011.5940480},
isbn = {978-1-4577-0890-9},
issn = {1931-0587},
keywords = {Benchmark testing,Daimler stereo-vision pedestrian detection,Detectors,HOG-linSVM classification component,ROI generation,ROI localization,Shape,Three dimensional displays,Training,Vehicles,automated highways,image classification,intelligent vehicles domain,noncommercial purposes,object detection,sensor vision,stereo image processing,urban environment},
language = {English},
mendeley-groups = {CV},
month = {jun},
pages = {691--696},
publisher = {IEEE},
title = {{A new benchmark for stereo-based pedestrian detection}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5940480},
year = {2011}
}
@inproceedings{Wang2013,
author = {Wang, Xiaoyu and Yang, Ming and Zhu, Shenghuo and Lin, Yuanqing},
booktitle = {2013 IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2013.10},
isbn = {978-1-4799-2840-8},
issn = {1550-5499},
keywords = {Boosting,DPM,Deformable models,Deformation,Detection,Feature extraction,ImageNet,ImageNet dataset,Layout,Object Detection,Object detection,PASCAL,PASCAL VOC 2007 dataset,Prototypes,Regionlet,Search problems,Subcategory,VOC 2010,arbitrary resolution,cascaded boosting classifier,deformable part-based model,descriptive object representations,detection mean average precision,detection window,feature extraction,feature extraction region,fine-grained spatial layouts,flexible object representations,generic object detection,image classification,image representation,local regions,multiclass detection benchmark datasets,object bounding box proposal,object categories,object classes,object detection,one-dimensional feature,regionlets,segmentation cues,tractable computations,visual databases},
language = {English},
mendeley-groups = {CV},
month = {dec},
pages = {17--24},
publisher = {IEEE},
title = {{Regionlets for Generic Object Detection}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6751111},
year = {2013}
}
@article{Long2014,
author = {Long, J and Shelhamer, E and Darrell, T},
file = {:Users/zhiconglu/Library/Application Support/Mendeley Desktop/Downloaded/Long, Shelhamer, Darrell - 2014 - Fully convolutional networks for semantic segmentation.pdf:pdf},
journal = {arXiv preprint arXiv:1411.4038},
mendeley-groups = {CV},
title = {{Fully convolutional networks for semantic segmentation}},
url = {http://arxiv.org/abs/1411.4038},
year = {2014}
}
@article{Krizhevsky2012,
author = {Krizhevsky, A and Sutskever, I and Hinton, GE},
journal = {Advances in Neural Information Processing Systems 25},
mendeley-groups = {CV},
title = {{Imagenet classification with deep convolutional neural networks}},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-w},
year = {2012}
}
@article{Huang2015,
abstract = {How can a single fully convolutional neural network (FCN) perform on object detection? We introduce DenseBox, a unified end-to-end FCN framework that directly predicts bounding boxes and object class confidences through all locations and scales of an image. Our contribution is two-fold. First, we show that a single FCN, if designed and optimized carefully, can detect multiple different objects extremely accurately and efficiently. Second, we show that when incorporating with landmark localization during multi-task learning, DenseBox further improves object detection accuray. We present experimental results on public benchmark datasets including MALF face detection and KITTI car detection, that indicate our DenseBox is the state-of-the-art system for detecting challenging objects such as faces and cars.},
archivePrefix = {arXiv},
arxivId = {1509.04874},
author = {Huang, Lichao and Yang, Yi and Deng, Yafeng and Yu, Yinan},
eprint = {1509.04874},
file = {:Users/zhiconglu/Library/Application Support/Mendeley Desktop/Downloaded/Huang et al. - 2015 - DenseBox Unifying Landmark Localization with End to End Object Detection.pdf:pdf},
journal = {arXiv},
mendeley-groups = {CV},
month = {sep},
title = {{DenseBox: Unifying Landmark Localization with End to End Object Detection}},
url = {http://arxiv.org/abs/1509.04874},
year = {2015}
}
@inproceedings{Geiger2012,
abstract = {Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. In this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection. Our recording platform is equipped with four high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system. Our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias by providing challenging benchmarks with novel difficulties to the computer vision community. Our benchmarks are available online at: www.cvlibs.net/datasets/kitti.},
author = {Geiger, A. and Lenz, P. and Urtasun, R.},
booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2012.6248074},
isbn = {978-1-4673-1228-8},
issn = {1063-6919},
keywords = {3D object detection,Benchmark testing,Cameras,KITTI vision benchmark suite,Measurement,Middlebury perform,Optical imaging,Optical sensors,SLAM,SLAM (robots),Velodyne laser scanner,Visualization,autonomous driving,high resolution video cameras,image sequences,object detection,optical flow image pairs,robot vision,stereo image processing,stereo visual odometry sequences,video signal processing,visual recognition systems},
mendeley-groups = {CV},
month = {jun},
pages = {3354--3361},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Are we ready for autonomous driving? The KITTI vision benchmark suite}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6248074},
year = {2012}
}
@inproceedings{Dollar2009,
abstract = {Pedestrian detection is a key problem in computer vision, with several applications including robotics, surveillance and automotive safety. Much of the progress of the past few years has been driven by the availability of challenging public datasets. To continue the rapid rate of innovation, we introduce the Caltech Pedestrian Dataset, which is two orders of magnitude larger than existing datasets. The dataset contains richly annotated video, recorded from a moving vehicle, with challenging images of low resolution and frequently occluded people. We propose improved evaluation metrics, demonstrating that commonly used per-window measures are flawed and can fail to predict performance on full images. We also benchmark several promising detection systems, providing an overview of state-of-the-art performance and a direct, unbiased comparison of existing methods. Finally, by analyzing common failure cases, we help identify future research directions for the field.},
author = {Dollar, P. and Wojek, C. and Schiele, B. and Perona, P.},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206631},
isbn = {978-1-4244-3992-8},
issn = {1063-6919},
keywords = {Application software,Automotive engineering,Caltech Pedestrian Dataset,Computer vision,Failure analysis,Image resolution,Robot vision systems,Safety,Surveillance,Technological innovation,Vehicles,annotated video,computer vision,image resolution,object detection,occluded people,pedestrian detection,traffic engineering computing,video signal processing},
mendeley-groups = {CV},
month = {jun},
pages = {304--311},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition, 2009. CVP},
title = {{Pedestrian detection: A benchmark}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5206631},
year = {2009}
}
@article{Tian2015,
author = {Tian, Y and Luo, P and Wang, X and Tang, X},
file = {:Users/zhiconglu/Library/Application Support/Mendeley Desktop/Downloaded/Tian et al. - Unknown - Deep Learning Strong Parts for Pedestrian Detection.pdf:pdf},
journal = {ICCV 2015},
mendeley-groups = {CV},
title = {{Deep Learning Strong Parts for Pedestrian Detection}},
url = {http://personal.ie.cuhk.edu.hk/{~}pluo/pdf/tianLWTiccv15.pdf},
year = {2015}
}

@inproceedings{van2011segmentation,
  title={Segmentation as selective search for object recognition},
  author={Van de Sande, Koen EA and Uijlings, Jasper RR and Gevers, Theo and Smeulders, Arnold WM},
  booktitle={Computer Vision (ICCV), 2011 IEEE International Conference on},
  pages={1879--1886},
  year={2011},
  organization={IEEE}
}